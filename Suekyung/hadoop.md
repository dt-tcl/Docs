(수정중)

# Hadoop 소개
![image](https://github.com/dt-tcl/Docs/new/master/Suekyung/image/hadoop.PNG?raw=true)
* 여러 대의 컴퓨터 클러스터에서 대규모 데이터 세트를 분산 처리 할 수 있게 해주는 자바 기반의 오픈소스 프레임워크
* 단일 서버에서 수천대의 머신으로 확장 가능(Scale Out)
* 초기에는 HDFS(Hadoop File System)과 MapReduce 프레임워크로 시작되었으나, 다양한 데이터 저장, 실행엔진, 프로그래밍 및 데이터 처리와 같은 하둡 생태계 전반(Hadoop Ecosustem)을 포함하는 의미로 확장됨.

## Hadoop 아키텍처

### HDFS 아키텍처
* HDFS는 네임노드와 데이터노드로 이루어져 있음.
* 네임노드
  * 네임노드는 HDFS에서 마스터역할을 하며, 메타데이터 관리와 데이터노드의 관리를 담당.
  * 메타데이터는 파일이름, 파일크기, 파일생성시간, 파일접근권한, 파일 소유자 및 그룹 소유자, 파일이 위치한 블록의 정보 등으로 구성.
* 데이터노드
  * 데이터노드는 Slave 역할을 하며, 파일을 저장하는 역할을 함.
  * 파일은 블록단위로 저장되며, 주기적으로 네임노드에 하트비트와 블록 리포트를 전달함.
  * 하트비트는 네임노드가 데이터노드의 동작여부를 판단하는데 이용.
  
## Hadoop Ecosystem
![image](https://github.com/dt-tcl/Docs/new/master/Suekyung/image/hadoop_eco.PNG?raw=true)
### 분산 리소스 관리
* YARN
  * 병렬처리를 위한 클러스터 자원(CPU, 메모리, 디스크 등) 관리 및 스케쥴링 담당.
  * MapReduce, Hive, Impala, Spark 등 다양한 Application들은 YARN에서 리소스를 할당받아 작업을 실행함.
  
### 데이터 저장
* HDFS
  * 분산 저장을 처리하기 위한 모듈
  * 여러 개의 서버를 하나의 서버처럼 묶어서 데이터를 저장
* HBase 
  * HDFS 기반의 칼럼 기반 데이터베이스
  * 구글 Bigtable을 기반응로 개발된 비관계형 데이터베이스이며, Hadoop 및 HDFS 위에 Bigtable과 같은 기능을 제공
  * 실시간 랜덤 조회 및 업데이트가 가능하며, 각 프로세스는 개인의 데이터를 비동기적으로 업데이트할 수 있음.
* Kudu
  * 칼럼 기반의 스토리지로 특정 칼럼에 대한 데이터 읽기를 고속화할 수 있음.
  * 기존 HDFS에서도 Parquet, RC, ORC와 같은 파일 포맷을 이용하면 칼럼 기반으로 데이터 저장이 가능하지만, HDFS 자체가 온라인 데이터 처리에 적합하지 않다는 약점이 있음.
  * HDFS 기반으로 온라인 처리가 가능한 HBase의 경우 데이터 분석 처리가 느리다는 단점이 있었음.
  * Kudu는 이러한 문제점을 보완하여 개발한 컬럼기반 스토리지로 데이터의 발생부터 분석까지의 시간을 단축할수 있음.
  
### 데이터 수집
* Flume
  * 분산된 서버에 에이전트를 설치하여, 에이전트로부터 데이터를 전달받는 Collector로 구성됨.
  * 전체 데이터의 흐름을 관리하는 마스터 서버가 있어 데이터의 수집위치, 전송방식, 저장위치를 동적으로 변경할 수 있음.
  * Cloudera 에서 개발했으며, 아파치 오픈소스 프로젝트로 공개되어 있음.
* Sqoop
  * HDFS, RDBMS, DW, NoSQL 등 다양한 저장소에 대용량 데이터를 신속하게 전송하는 방법 제공
  * Oracle, MS-SQL, DB2 등과 같은 상용 RDBMS 및 MySQL, PostgreSQL과 같은 오픈소스 RDBMS 등을 지원함.
* Kafka
  * 데이터 스트림을 싥시간으로 관리하기 위한 분산 메세징 시스템
  * 2011년 링크드인에서 자사의 대용량 이벤트 처리를 위해 개발됨.
  * 파티셔닝을 지원하기 때문에 다수의 Kafka 서버에서 메시지를 분산처리할 수 있으며, 시스템 안정성을 위해 Load Balancing과 Fault Tolerent를 보장함.
  * 다수의 글로벌 기업들이 사용중이며, 그 중 링크드인은 하루에 1조 1천억 건 이상의 메세지를 처리하고 있음.

### 데이터 처리
* Spark
  * 인메모리 기반의 범용 데이터 처리 플랫폼
  * 배치 처리, 머신러닝, SQL 질의 처리, 스트리밍 데이터 처리, 그래프 라이브러리 처리와 같은 다양한 작업을 수용할 수 있도록 설계되어 있음.
* Impala 
  * Cloudera에서 개발한 하둡 기반의 분산 쿼리 엔진
  * MapReduce를 사용하지 않고 C++로 개발한 인메모리 엔진을 사용해 빠른 성능을 보여줌.
  * 데이터 조회를 위한 인터페이스로 HiveQL을 사용하며, 수초 내에 SQL 질의 결과를 확인할 수 있음.
* Hive
  * 하둡기반 데이터 솔루션으로 자바를 모르는 데이터 분석가들도 쉽게 하둡 데이터 분석을 할 수 있도록 도와줌.
  * SQL과 매우 유사한 HiveQL 이라는 쿼리언어 제공
  * HiveQL은 내부적으로 MapReduce 잡으로 변환되어 실행됨.
* MapReduce
  * 분산되어 저장된 데이터를 병렬 처리할 수 있게 해주는 분산 처리 모듈.

### 분산 코디네이터
* Zookeeper
  * 분산 환경에서 서버 간의 상호 조정이 필요한 다양한 서비스를 제공하는 시스템.
  * 하나의 서버에만 서비스가 집중되지 않게 서비스를 알맞게 분산하여 동시에 처리하게 해줌.
  * 하나의 서버에서 처리한 결과를 다른 서버와도 동기화해서 데이터의 안정성 보장
  * 운영 서버에 문제가 발생해서 서비스 제공이 불가능할 경우, 대기중인 서버를 운영 서버로 바꾸어 서비스 중단없이 제공되게 함.

### 워크플로우 관리
* Oozie
  * 하둡 작업을 관리하는 워크플로우 및 코디네이터 시스템
  * 자바 서블릿 컨테이너에서 실행되는 자바 웹 애플리케이션 서버이며, 맵리듀스 작업에 특화된 액션으로 구성된 워크플로우를 제어함.

### 데이터 시각화
* Zeppelin
  * 빅데이터 분석가를 위한 웹 기반의 분석 도구이며, 분석 결과를 즉시 표, 그래프로 표현하는 시각화까지 지원
  * iPython의 Notebook과 유사한 기능을 제공하며, 분석가는 이를통해 손쉽게 데이터를 추출, 정제, 분석, 공유할 수 있ㅇ므.
  * Spark, Hive, Flink, ElasticSearch, DBMS 등 다양한 분석 플랫폼과 연동 간으.
  
